{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "import json\n",
    "\n",
    "# LangGraph pour l'architecture en étapes/noeuds\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# LangChain pour la génération de recommandations\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Récuépration des variables d'environnement (clé API)\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "## Création d'un client OpenAI pour la génération de recommandations\n",
    "client = OpenAI()\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "## Document en entrée\n",
    "json_file = \"Data/rapport.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sortie pour les anomalies\n",
    "class Anomalies(BaseModel):\n",
    "    metric: str = Field(description=\"Métrique ou élément où il y a une anomalie\")\n",
    "    value: Any = Field(description=\"La valeur qui pose problème\")\n",
    "    issue: str = Field(description=\"Les conséquences ou explications de la valeur problématique\")\n",
    "    \n",
    "## Sortie pour les recommendations\n",
    "class Recommendations(BaseModel):\n",
    "    anomalie: str = Field(description=\"Description d'anomalie.s rencontrée.S\")\n",
    "    suggestion: str = Field(description=\"Action.s suggérée.s pour optimiser l'infrastructure\")\n",
    "\n",
    "class RecommendationList(BaseModel):\n",
    "    recommendations: List[Recommendations] = Field(description=\"Une liste de recommandations d'optimisation basées sur les anomalies détectées.\")\n",
    "\n",
    "    \n",
    "## Définition de l'état du graphe : InputState pour la gestion de l'entrée et OutputState pour la gestion de la sortie\n",
    "class State(TypedDict):\n",
    "    input_path: str                 \n",
    "    input_data: Optional[List[Dict[str, Any]]] \n",
    "    anomalies: List[Anomalies]     \n",
    "    recommendations: RecommendationList\n",
    "    error: Optional[str]   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fonctions pour chaque étape de l'architecture\n",
    "\n",
    "def data_ingestion(state):\n",
    "    \"\"\" Noeud d'ingestion des données \"\"\"\n",
    "    print(\"### Noeud en cours : Ingestion des données ###\")\n",
    "    print(\"\\tSTATE : \", state)\n",
    "    try :\n",
    "        if \".json\" in state[\"input_data\"] : \n",
    "            with open(state[\"input_data\"], 'r') as file :\n",
    "                data = json.load(file)\n",
    "            print(f\"Data ingestion complétée pour le fichier : { state['input_data'] }\\n\")\n",
    "\n",
    "        else :\n",
    "            data = state[\"input_data\"]\n",
    "            print(f\"Data ingestion complétée\")\n",
    "        return {**state, \"input_data\": data, \"error\": None}\n",
    "        \n",
    "    except Exception as e :\n",
    "        print(f\"Erreur pendant l'ingestion du fichier : {e}\\n\")\n",
    "        return {**state, \"input_data\": {}, \"error\": f\"Ingestion failed: {str(e)}\"}\n",
    "    \n",
    "\n",
    "def anomalies_detection(state):\n",
    "    \"\"\" Noeud de détection d'anomalies dans les donées \"\"\"\n",
    "    print(\"\\n\\n### Noeud en cours : Détection des anomalies ###\")\n",
    "    print(\"\\tSTATE : \", state)\n",
    "\n",
    "    if state[\"error\"] != None:\n",
    "        print(\"Erreur détectée dans un noeud précédent. Arrêt de la génération de recommandations\\n\")\n",
    "        return state\n",
    "    \n",
    "    if type(state[\"input_data\"]) == dict : \n",
    "        state[\"input_data\"] = [state[\"input_data\"]]\n",
    "    data = state[\"input_data\"]\n",
    "    anomalies_detected: List[Anomalies] = []\n",
    "        \n",
    "    for d in data :\n",
    "        if d[\"cpu_usage\"] > 80 :\n",
    "            anomalies_detected.append({\"metric\": \"cpu_usage\",\"value\": d[\"cpu_usage\"],\"issue\": \"High CPU Usage (> 80%)\"})\n",
    "        if d[\"memory_usage\"] > 80 :\n",
    "            anomalies_detected.append({\"metric\": \"memory_usage\",\"value\": d[\"memory_usage\"],\"issue\": \"High Memory Usage (> 80%)\"})\n",
    "\n",
    "        service_status = d[\"service_status\"]\n",
    "        for service, status in service_status.items():\n",
    "            if status != \"online\":\n",
    "                anomalies_detected.append({\"metric\": f\"service_status : {service}\", \"value\": status, \"issue\": f\"Service {service} is {status}\"})\n",
    "        \n",
    "    print(f\"{len(anomalies_detected)} anomalie.s détectée.s\")\n",
    "    print(\"\\n\\tANOMALIES DETECTED \", anomalies_detected)\n",
    "    state[\"anomalies\"] = anomalies_detected\n",
    "    return state\n",
    "\n",
    "def recommandations_generation(state):\n",
    "    \"\"\" Noeud de génération de recommandations à partir des anomalies détectées \"\"\"\n",
    "    print(\"\\n\\n### Noeud en cours : Génération de recommandations ###\")\n",
    "    print(\"STATE : \", state)\n",
    "    \n",
    "    if state[\"error\"] != None:\n",
    "        print(\"Erreur détectée dans un noeud précédent. Arrêt de la génération de recommandations\")\n",
    "        return state\n",
    "    \n",
    "    anomalies = state[\"anomalies\"]    \n",
    "    recommendations: List[Recommendations] = [] \n",
    "    parser = PydanticOutputParser(pydantic_object=RecommendationList)\n",
    "    prompt_template = ChatPromptTemplate.from_messages([(\"system\",\n",
    "                                                         \"Tu es un ingénieur infrastructure expert analysant des anomalies de monitoring. \"\n",
    "                                                         \"Ta tâche est de fournir des recommandations d'optimisation concrètes et actionnables basées sur les anomalies détectées,. \"\n",
    "                                                         \"Structure ta réponse exactement selon le schéma JSON fourni.\"\n",
    "                                                         \"\\n{format_instructions}\"), \n",
    "                                                         (\"human\", \n",
    "                                                          \"Voici les anomalies détectées sur l'infrastructure :\\n\"\n",
    "                                                          \"{anomaly_list}\\n\\n\"\n",
    "                                                          \"Génère une liste de recommandations pour traiter ces problèmes, dans un seul texte.  Pour chaque anomalie, fournis un seul objet `Recommendations` \"\n",
    "                                                          \"où le champ 'suggestion' regroupe toutes les actions proposées pour cette anomalie, séparées par un saut de ligne et listées par des numéros.\")\n",
    "                                                        ])\n",
    "        \n",
    "    chain = prompt_template | llm | parser\n",
    "    \n",
    "\n",
    "    if anomalies == []:\n",
    "        print(\"Aucune anomalie trouvée dans l'état. Pas de recommandations à générer.\")\n",
    "        return {**state, \"recommendations\": []}\n",
    "    \n",
    "    for a in anomalies:\n",
    "        formatted_anomalies = f\"- Métrique: {a['metric']}, Valeur: {a['value']}, Problème: {a['issue']}\"\n",
    "        try:\n",
    "            print(\"Appel du LLM (gpt-4o-mini) pour générer les recommandations...\")\n",
    "            response = chain.invoke({\n",
    "                \"format_instructions\": parser.get_format_instructions(), \n",
    "                \"anomaly_list\": formatted_anomalies\n",
    "            })\n",
    "            \n",
    "            # recommendations.append(response.recommendations)\n",
    "            recommendations.append({\"anomalie\" : response.recommendations[0].anomalie, \"suggestion\": response.recommendations[0].suggestion})\n",
    "            print(f\"Génération réussie de {len(recommendations)} recommandations.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors de l'appel LLM ou du parsing de la réponse : {e}\")\n",
    "            return {**state, \"recommendations\": [], \"error\": f\"Génération de recommandations a échoué: {str(e)}\"}\n",
    "\n",
    "    state[\"recommendations\"] = recommendations\n",
    "    print(\"FINAL STATE : \", state)\n",
    "    return state\n",
    "\n",
    "def file_creation(state):\n",
    "    print(\"\\n\\n### Noeud en cours : Création d'un fichier avec les anomalies et les recommandations (état final du graphe) ###\")\n",
    "    print(\"FINAL STATE : \", state)\n",
    "\n",
    "    with open(\"Recommendations/recommandations.json\", \"w\") as outfile:\n",
    "        json.dump(state, outfile, indent=4, sort_keys=False, ensure_ascii=False).encode('utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Définition du graphe\n",
    "# Initialisation du graphe\n",
    "workflow = StateGraph(State) #, input=InputState, output=OutputState)\n",
    "\n",
    "# Définition des noeuds du graphe\n",
    "workflow.add_node(\"ingestion\", data_ingestion)\n",
    "workflow.add_node(\"analyze\", anomalies_detection)\n",
    "workflow.add_node(\"recommend\", recommandations_generation)\n",
    "workflow.add_node(\"file_creation\", file_creation)\n",
    "\n",
    "# Début du graphe\n",
    "workflow.set_entry_point(\"ingestion\")\n",
    "\n",
    "# Définition des arêtes du graphe\n",
    "workflow.add_edge(\"ingestion\", \"analyze\")\n",
    "workflow.add_edge(\"analyze\", \"recommend\")\n",
    "# workflow.add_edge(\"recommend\", END)\n",
    "workflow.add_edge(\"recommend\", \"file_creation\")\n",
    "workflow.add_edge(\"file_creation\", END)\n",
    "\n",
    "# Compilation du graphe\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Noeud en cours : Ingestion des données ###\n",
      "\tSTATE :  {'input_data': {'timestamp': '2023-10-01T15:00:00Z', 'cpu_usage': 73, 'memory_usage': 79, 'latency_ms': 213, 'disk_usage': 77, 'network_in_kbps': 1506, 'network_out_kbps': 1618, 'io_wait': 6, 'thread_count': 165, 'active_connections': 73, 'error_rate': 0.04, 'uptime_seconds': 370800, 'temperature_celsius': 67, 'power_consumption_watts': 290, 'service_status': {'database': 'online', 'api_gateway': 'degraded', 'cache': 'degraded'}}}\n",
      "Data ingestion complétée\n",
      "\n",
      "\n",
      "### Noeud en cours : Détection des anomalies ###\n",
      "\tSTATE :  {'input_data': {'timestamp': '2023-10-01T15:00:00Z', 'cpu_usage': 73, 'memory_usage': 79, 'latency_ms': 213, 'disk_usage': 77, 'network_in_kbps': 1506, 'network_out_kbps': 1618, 'io_wait': 6, 'thread_count': 165, 'active_connections': 73, 'error_rate': 0.04, 'uptime_seconds': 370800, 'temperature_celsius': 67, 'power_consumption_watts': 290, 'service_status': {'database': 'online', 'api_gateway': 'degraded', 'cache': 'degraded'}}, 'error': None}\n",
      "2 anomalie.s détectée.s\n",
      "\n",
      "\tANOMALIES DETECTED  [{'metric': 'service_status : api_gateway', 'value': 'degraded', 'issue': 'Service api_gateway is degraded'}, {'metric': 'service_status : cache', 'value': 'degraded', 'issue': 'Service cache is degraded'}]\n",
      "\n",
      "\n",
      "### Noeud en cours : Génération de recommandations ###\n",
      "STATE :  {'input_data': [{'timestamp': '2023-10-01T15:00:00Z', 'cpu_usage': 73, 'memory_usage': 79, 'latency_ms': 213, 'disk_usage': 77, 'network_in_kbps': 1506, 'network_out_kbps': 1618, 'io_wait': 6, 'thread_count': 165, 'active_connections': 73, 'error_rate': 0.04, 'uptime_seconds': 370800, 'temperature_celsius': 67, 'power_consumption_watts': 290, 'service_status': {'database': 'online', 'api_gateway': 'degraded', 'cache': 'degraded'}}], 'anomalies': [{'metric': 'service_status : api_gateway', 'value': 'degraded', 'issue': 'Service api_gateway is degraded'}, {'metric': 'service_status : cache', 'value': 'degraded', 'issue': 'Service cache is degraded'}], 'error': None}\n",
      "Appel du LLM (gpt-4o-mini) pour générer les recommandations...\n",
      "Génération réussie de 1 recommandations.\n",
      "Appel du LLM (gpt-4o-mini) pour générer les recommandations...\n",
      "Génération réussie de 2 recommandations.\n",
      "FINAL STATE :  {'input_data': [{'timestamp': '2023-10-01T15:00:00Z', 'cpu_usage': 73, 'memory_usage': 79, 'latency_ms': 213, 'disk_usage': 77, 'network_in_kbps': 1506, 'network_out_kbps': 1618, 'io_wait': 6, 'thread_count': 165, 'active_connections': 73, 'error_rate': 0.04, 'uptime_seconds': 370800, 'temperature_celsius': 67, 'power_consumption_watts': 290, 'service_status': {'database': 'online', 'api_gateway': 'degraded', 'cache': 'degraded'}}], 'anomalies': [{'metric': 'service_status : api_gateway', 'value': 'degraded', 'issue': 'Service api_gateway is degraded'}, {'metric': 'service_status : cache', 'value': 'degraded', 'issue': 'Service cache is degraded'}], 'error': None, 'recommendations': [{'anomalie': 'Service api_gateway is degraded', 'suggestion': \"1. Vérifiez les logs du service api_gateway pour identifier les erreurs spécifiques.\\n2. Augmentez les ressources (CPU, mémoire) allouées au service api_gateway pour améliorer ses performances.\\n3. Mesurez la latence du service pour détecter d'éventuels goulets d'étranglement.\\n4. Vérifiez les dépendances externes du service pour s'assurer qu'elles répondent correctement.\\n5. Envisagez de redémarrer le service api_gateway si les performances ne s'améliorent pas après les ajustements initiaux.\"}, {'anomalie': 'Service cache is degraded', 'suggestion': \"1. Vérifiez les logs du service cache pour identifier des erreurs potentielles.\\\\n2. Augmentez les ressources (CPU, mémoire) allouées au service cache.\\\\n3. Examinez la configuration du cache pour s'assurer qu'elle est optimisée.\\\\n4. Redémarrez le service cache si nécessaire après avoir apporté des modifications.\\\\n5. Mettez en place une surveillance plus fine pour anticiper de futures dégradations.\"}]}\n",
      "\n",
      "\n",
      "### Noeud en cours : Création d'un fichier avec les anomalies et les recommandations (état final du graphe) ###\n",
      "FINAL STATE :  {'input_data': [{'timestamp': '2023-10-01T15:00:00Z', 'cpu_usage': 73, 'memory_usage': 79, 'latency_ms': 213, 'disk_usage': 77, 'network_in_kbps': 1506, 'network_out_kbps': 1618, 'io_wait': 6, 'thread_count': 165, 'active_connections': 73, 'error_rate': 0.04, 'uptime_seconds': 370800, 'temperature_celsius': 67, 'power_consumption_watts': 290, 'service_status': {'database': 'online', 'api_gateway': 'degraded', 'cache': 'degraded'}}], 'anomalies': [{'metric': 'service_status : api_gateway', 'value': 'degraded', 'issue': 'Service api_gateway is degraded'}, {'metric': 'service_status : cache', 'value': 'degraded', 'issue': 'Service cache is degraded'}], 'recommendations': [{'anomalie': 'Service api_gateway is degraded', 'suggestion': \"1. Vérifiez les logs du service api_gateway pour identifier les erreurs spécifiques.\\n2. Augmentez les ressources (CPU, mémoire) allouées au service api_gateway pour améliorer ses performances.\\n3. Mesurez la latence du service pour détecter d'éventuels goulets d'étranglement.\\n4. Vérifiez les dépendances externes du service pour s'assurer qu'elles répondent correctement.\\n5. Envisagez de redémarrer le service api_gateway si les performances ne s'améliorent pas après les ajustements initiaux.\"}, {'anomalie': 'Service cache is degraded', 'suggestion': \"1. Vérifiez les logs du service cache pour identifier des erreurs potentielles.\\\\n2. Augmentez les ressources (CPU, mémoire) allouées au service cache.\\\\n3. Examinez la configuration du cache pour s'assurer qu'elle est optimisée.\\\\n4. Redémarrez le service cache si nécessaire après avoir apporté des modifications.\\\\n5. Mettez en place une surveillance plus fine pour anticiper de futures dégradations.\"}], 'error': None}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[108]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m2023-10-01T15:00:00Z\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu_usage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m73\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_usage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m79\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatency_ms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m213\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisk_usage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m77\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnetwork_in_kbps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1506\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnetwork_out_kbps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1618\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mio_wait\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_count\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m165\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactive_connections\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m73\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.04\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muptime_seconds\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m370800\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature_celsius\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m67\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpower_consumption_watts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m290\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_status\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatabase\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43monline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapi_gateway\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdegraded\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdegraded\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m    \u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ecaruana\\AppData\\Local\\anaconda3\\envs\\agent_env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2683\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   2681\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2682\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m2683\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2684\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2687\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2688\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2689\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2691\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2692\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2693\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ecaruana\\AppData\\Local\\anaconda3\\envs\\agent_env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2331\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2325\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2326\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2327\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2328\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2329\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2331\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2334\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2337\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2338\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2339\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ecaruana\\AppData\\Local\\anaconda3\\envs\\agent_env\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    144\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ecaruana\\AppData\\Local\\anaconda3\\envs\\agent_env\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ecaruana\\AppData\\Local\\anaconda3\\envs\\agent_env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m config = patch_config(\n\u001b[32m    603\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    604\u001b[39m )\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ecaruana\\AppData\\Local\\anaconda3\\envs\\agent_env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mfile_creation\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFINAL STATE : \u001b[39m\u001b[33m\"\u001b[39m, state)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRecommendations/recommandations.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outfile:\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'encode'",
      "During task with name 'file_creation' and id 'ec4cd21a-ab46-b7d2-6b3d-9181281ce2aa'"
     ]
    }
   ],
   "source": [
    "graph.invoke({\"input_data\" : {\n",
    "    \"timestamp\": \"2023-10-01T15:00:00Z\",\n",
    "    \"cpu_usage\": 73,\n",
    "    \"memory_usage\": 79,\n",
    "    \"latency_ms\": 213,\n",
    "    \"disk_usage\": 77,\n",
    "    \"network_in_kbps\": 1506,\n",
    "    \"network_out_kbps\": 1618,\n",
    "    \"io_wait\": 6,\n",
    "    \"thread_count\": 165,\n",
    "    \"active_connections\": 73,\n",
    "    \"error_rate\": 0.04,\n",
    "    \"uptime_seconds\": 370800,\n",
    "    \"temperature_celsius\": 67,\n",
    "    \"power_consumption_watts\": 290,\n",
    "    \"service_status\": {\n",
    "      \"database\": \"online\",\n",
    "      \"api_gateway\": \"degraded\",\n",
    "      \"cache\": \"degraded\"}\n",
    "    }\n",
    "  }    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"input_data\" : json_file}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_env",
   "language": "python",
   "name": "agent_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
